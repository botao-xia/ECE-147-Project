{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b24e767-f188-4a27-8eff-ffd16fa731df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from train import train_loop\n",
    "from data_module import EEGDataModule\n",
    "from model import ViTransformer, LSTM, ConvLSTM, DeepConvNet, RNN, LSTM, ShallowConvNet\n",
    "from ATCNet import ATCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75d93f99-2d57-47c9-8b29-a22efbdf2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e78fa79-6161-429e-9faa-0f71d85f8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6cb696c-7808-4c47-826d-640e3116164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import mean_max_subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96707763-f722-4806-9960-9036c03476bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"train_epochs\": 10,\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"test_size\": 0.2,\n",
    "    \"random_state\": 42,\n",
    "    \"data_dir\": \"../../Data/\",\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5ecccf7-e10f-4054-ba15-28fe119cc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataModule(args=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03cfc735-4206-4b77-98e3-b681a4021765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_module:Training data shape: (1692, 22, 1000)\n",
      "INFO:data_module:Training labels shape: (1692,)\n"
     ]
    }
   ],
   "source": [
    "dataset.setup(transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2ccad1d-306e-4921-922c-ffd7614c778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_module:loaded 1692 train data instances\n",
      "INFO:data_module:loaded 423 train data instances\n"
     ]
    }
   ],
   "source": [
    "train, valid = dataset.train_dataloader(), dataset.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f36cd515-5df8-4d5f-b3f3-d66381201704",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ATCNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64b4275f-cda8-46f6-995f-ccf43196bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "ATCNet                                                  --\n",
      "├─Convolution_module: 1-1                               --\n",
      "│    └─Conv2d: 2-1                                      1,024\n",
      "│    └─BatchNorm2d: 2-2                                 32\n",
      "│    └─Conv2d: 2-3                                      704\n",
      "│    └─BatchNorm2d: 2-4                                 64\n",
      "│    └─ELU: 2-5                                         --\n",
      "│    └─AvgPool2d: 2-6                                   --\n",
      "│    └─AvgPool2d: 2-7                                   --\n",
      "│    └─Dropout: 2-8                                     --\n",
      "│    └─Dropout: 2-9                                     --\n",
      "│    └─Conv2d: 2-10                                     16,384\n",
      "│    └─BatchNorm2d: 2-11                                64\n",
      "├─ModuleList: 1-2                                       --\n",
      "│    └─MultiheadAttention: 2-12                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-1        1,056\n",
      "│    └─MultiheadAttention: 2-13                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-2        1,056\n",
      "│    └─MultiheadAttention: 2-14                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-3        1,056\n",
      "│    └─MultiheadAttention: 2-15                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-4        1,056\n",
      "│    └─MultiheadAttention: 2-16                         3,168\n",
      "│    │    └─NonDynamicallyQuantizableLinear: 3-5        1,056\n",
      "├─ModuleList: 1-3                                       --\n",
      "│    └─TCN: 2-17                                        --\n",
      "│    │    └─ModuleList: 3-6                             8,256\n",
      "│    │    └─ModuleList: 3-7                             8,256\n",
      "│    │    └─ModuleList: 3-8                             128\n",
      "│    │    └─ModuleList: 3-9                             128\n",
      "│    │    └─ModuleList: 3-10                            --\n",
      "│    │    └─ELU: 3-11                                   --\n",
      "│    └─TCN: 2-18                                        --\n",
      "│    │    └─ModuleList: 3-12                            8,256\n",
      "│    │    └─ModuleList: 3-13                            8,256\n",
      "│    │    └─ModuleList: 3-14                            128\n",
      "│    │    └─ModuleList: 3-15                            128\n",
      "│    │    └─ModuleList: 3-16                            --\n",
      "│    │    └─ELU: 3-17                                   --\n",
      "│    └─TCN: 2-19                                        --\n",
      "│    │    └─ModuleList: 3-18                            8,256\n",
      "│    │    └─ModuleList: 3-19                            8,256\n",
      "│    │    └─ModuleList: 3-20                            128\n",
      "│    │    └─ModuleList: 3-21                            128\n",
      "│    │    └─ModuleList: 3-22                            --\n",
      "│    │    └─ELU: 3-23                                   --\n",
      "│    └─TCN: 2-20                                        --\n",
      "│    │    └─ModuleList: 3-24                            8,256\n",
      "│    │    └─ModuleList: 3-25                            8,256\n",
      "│    │    └─ModuleList: 3-26                            128\n",
      "│    │    └─ModuleList: 3-27                            128\n",
      "│    │    └─ModuleList: 3-28                            --\n",
      "│    │    └─ELU: 3-29                                   --\n",
      "│    └─TCN: 2-21                                        --\n",
      "│    │    └─ModuleList: 3-30                            8,256\n",
      "│    │    └─ModuleList: 3-31                            8,256\n",
      "│    │    └─ModuleList: 3-32                            128\n",
      "│    │    └─ModuleList: 3-33                            128\n",
      "│    │    └─ModuleList: 3-34                            --\n",
      "│    │    └─ELU: 3-35                                   --\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─LazyLinear: 2-22                                 --\n",
      "│    └─LazyLinear: 2-23                                 --\n",
      "│    └─LazyLinear: 2-24                                 --\n",
      "│    └─LazyLinear: 2-25                                 --\n",
      "│    └─LazyLinear: 2-26                                 --\n",
      "================================================================================\n",
      "Total params: 123,232\n",
      "Trainable params: 123,232\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# Only uses outputs of modules.\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed85ceb9-9bdf-4d03-a123-59a7f5a54736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██                            | 7/100 [00:06<01:27,  1.06it/s, acc=0.423, val_acc=0.253]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-66945044ff71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ECE-147-Project/EEG/src/train.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dataloader, val_dataloader, device, optimizer, criterion, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# necessary if X is not on the same device as model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mval_loss_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECE-147-Project/EEG/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x is in batch, n_features, seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, seq_len, n_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# obtain the last output of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m    477\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                                       self.batch_first)\n\u001b[0m\u001b[1;32m    479\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_hist, acc_hist, val_loss_hist, val_acc_hist = train_loop(model, train, valid, device, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4e88bc-98a1-42dd-bc2f-97c50f4b2121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(val_acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "146dbfa9-9e50-4d89-8b13-d632cceeb219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663120567375887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_hist[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cb8ce-ee51-40b4-bbc0-5e5f0d6253a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
